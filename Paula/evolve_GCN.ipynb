{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import pandas as pd\n",
    "from dgl.nn import GraphConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load datasets\n",
    "df_classes = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_classes.csv\")\n",
    "df_edges = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_edgelist.csv\")\n",
    "df_features = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_features.csv\", header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = df_classes[df_classes['class'] != \"unknown\"]\n",
    "# Change column names --> Column 1 is txId, Column 2 is timestep and the rest are unknown features\n",
    "df_features.columns = ['txId', 'timestep'] + ['f' + str(i) for i in range(165)]\n",
    "\n",
    "# Remove all edges that do not appear in classesDF\n",
    "df_features = df_features[df_features['txId'].isin(df_classes['txId'])]\n",
    "\n",
    "df_edges = df_edges[df_edges['txId1'].isin(df_classes['txId']) & df_edges['txId2'].isin(df_classes['txId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica los nodos en df_classes y df_features\n",
    "nodos_classes = set(df_classes['txId'])\n",
    "nodos_features = set(df_features['txId'])\n",
    "\n",
    "# Encuentra la intersección de nodos entre clases y características\n",
    "nodos_comunes = nodos_classes.intersection(nodos_features)\n",
    "\n",
    "# Filtrar df_edges para asegurar que ambos nodos de cada arista estén en nodos_comunes\n",
    "df_edges = df_edges[df_edges['txId1'].isin(nodos_comunes) & df_edges['txId2'].isin(nodos_comunes)]\n",
    "\n",
    "# Filtrar df_features y df_classes para incluir solo los nodos comunes\n",
    "df_features = df_features[df_features['txId'].isin(nodos_comunes)]\n",
    "df_classes = df_classes[df_classes['txId'].isin(nodos_comunes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarte de que df_edges solo contiene nodos presentes en los otros DataFrames\n",
    "assert all(df_edges['txId1'].isin(df_features['txId']))\n",
    "assert all(df_edges['txId2'].isin(df_features['txId']))\n",
    "\n",
    "# Verificar que df_features y df_classes contienen los mismos nodos\n",
    "assert set(df_features['txId']) == set(df_classes['txId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We assign 0 to ilicit transacions and 1 to licit ones\n",
    "df_classes['class'] = df_classes['class'].replace({'1': 0, '2': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos únicos en df_classes: 46564\n",
      "Nodos únicos en df_edges: 35874\n",
      "Nodos únicos en df_features: 46564\n"
     ]
    }
   ],
   "source": [
    "unique_nodes_classes = df_classes['txId'].nunique()\n",
    "\n",
    "unique_nodes_edges = pd.concat([df_edges['txId1'], df_edges['txId2']]).nunique()\n",
    "\n",
    "unique_nodes_features = df_features['txId'].nunique()\n",
    "\n",
    "# Imprimir el número de nodos únicos en cada dataset\n",
    "print(f\"Nodos únicos en df_classes: {unique_nodes_classes}\")\n",
    "print(f\"Nodos únicos en df_edges: {unique_nodes_edges}\")\n",
    "print(f\"Nodos únicos en df_features: {unique_nodes_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindexar los nodos para que empicen desde 0\n",
    "node_mapping = {old_id: new_id for new_id, old_id in enumerate(df_features['txId'].unique())}\n",
    "\n",
    "# Aplicar este mapeo a df_edges para actualizar los identificadores de nodos a la nueva secuencia\n",
    "df_edges['txId1'] = df_edges['txId1'].map(node_mapping)\n",
    "df_edges['txId2'] = df_edges['txId2'].map(node_mapping)\n",
    "\n",
    "# Ahora, cuando crees el grafo y asignes características y etiquetas, el tamaño debería coincidir\n",
    "g = dgl.graph((df_edges['txId1'].values, df_edges['txId2'].values))\n",
    "g.ndata['feat'] = torch.tensor(df_features.iloc[:, 2:].values, dtype=torch.float32)  # Asumiendo que las dos primeras columnas no son características\n",
    "g.ndata['label'] = torch.tensor(df_classes['class'].astype(int).values, dtype=torch.long)  # Asegurándonos de que las clases están en formato numérico\n",
    "\n",
    "# Definir el modelo GCN\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats, allow_zero_in_degree=True)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# Instanciar y entrenar el modelo\n",
    "model = GCNModel(g.ndata['feat'].shape[1], 16, 2)  # Asumiendo 2 clases (lícito, ilícito) y omitiendo 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8107, Train Acc: 0.8263\n",
      "Epoch 1, Loss: 0.6477, Train Acc: 0.8711\n",
      "Epoch 2, Loss: 0.5877, Train Acc: 0.8812\n",
      "Epoch 3, Loss: 0.5585, Train Acc: 0.8866\n",
      "Epoch 4, Loss: 0.5394, Train Acc: 0.8906\n",
      "Epoch 5, Loss: 0.5244, Train Acc: 0.8937\n",
      "Epoch 6, Loss: 0.5116, Train Acc: 0.8969\n",
      "Epoch 7, Loss: 0.5002, Train Acc: 0.8997\n",
      "Epoch 8, Loss: 0.4901, Train Acc: 0.9023\n",
      "Epoch 9, Loss: 0.4811, Train Acc: 0.9036\n",
      "Epoch 10, Loss: 0.4729, Train Acc: 0.9043\n",
      "Epoch 11, Loss: 0.4655, Train Acc: 0.9055\n",
      "Epoch 12, Loss: 0.4586, Train Acc: 0.9065\n",
      "Epoch 13, Loss: 0.4521, Train Acc: 0.9070\n",
      "Epoch 14, Loss: 0.4461, Train Acc: 0.9074\n",
      "Epoch 15, Loss: 0.4405, Train Acc: 0.9077\n",
      "Epoch 16, Loss: 0.4352, Train Acc: 0.9082\n",
      "Epoch 17, Loss: 0.4302, Train Acc: 0.9081\n",
      "Epoch 18, Loss: 0.4255, Train Acc: 0.9081\n",
      "Epoch 19, Loss: 0.4210, Train Acc: 0.9083\n",
      "Epoch 20, Loss: 0.4166, Train Acc: 0.9083\n",
      "Epoch 21, Loss: 0.4124, Train Acc: 0.9083\n",
      "Epoch 22, Loss: 0.4084, Train Acc: 0.9085\n",
      "Epoch 23, Loss: 0.4044, Train Acc: 0.9086\n",
      "Epoch 24, Loss: 0.4005, Train Acc: 0.9088\n",
      "Epoch 25, Loss: 0.3967, Train Acc: 0.9090\n",
      "Epoch 26, Loss: 0.3931, Train Acc: 0.9092\n",
      "Epoch 27, Loss: 0.3895, Train Acc: 0.9092\n",
      "Epoch 28, Loss: 0.3861, Train Acc: 0.9093\n",
      "Epoch 29, Loss: 0.3828, Train Acc: 0.9095\n",
      "Epoch 30, Loss: 0.3796, Train Acc: 0.9095\n",
      "Epoch 31, Loss: 0.3765, Train Acc: 0.9095\n",
      "Epoch 32, Loss: 0.3736, Train Acc: 0.9095\n",
      "Epoch 33, Loss: 0.3707, Train Acc: 0.9096\n",
      "Epoch 34, Loss: 0.3679, Train Acc: 0.9097\n",
      "Epoch 35, Loss: 0.3652, Train Acc: 0.9098\n",
      "Epoch 36, Loss: 0.3626, Train Acc: 0.9098\n",
      "Epoch 37, Loss: 0.3601, Train Acc: 0.9098\n",
      "Epoch 38, Loss: 0.3577, Train Acc: 0.9098\n",
      "Epoch 39, Loss: 0.3554, Train Acc: 0.9098\n",
      "Epoch 40, Loss: 0.3532, Train Acc: 0.9098\n",
      "Epoch 41, Loss: 0.3510, Train Acc: 0.9100\n",
      "Epoch 42, Loss: 0.3490, Train Acc: 0.9100\n",
      "Epoch 43, Loss: 0.3470, Train Acc: 0.9100\n",
      "Epoch 44, Loss: 0.3450, Train Acc: 0.9100\n",
      "Epoch 45, Loss: 0.3432, Train Acc: 0.9100\n",
      "Epoch 46, Loss: 0.3414, Train Acc: 0.9101\n",
      "Epoch 47, Loss: 0.3397, Train Acc: 0.9101\n",
      "Epoch 48, Loss: 0.3380, Train Acc: 0.9102\n",
      "Epoch 49, Loss: 0.3364, Train Acc: 0.9102\n",
      "Epoch 50, Loss: 0.3348, Train Acc: 0.9102\n",
      "Epoch 51, Loss: 0.3333, Train Acc: 0.9103\n",
      "Epoch 52, Loss: 0.3317, Train Acc: 0.9103\n",
      "Epoch 53, Loss: 0.3303, Train Acc: 0.9104\n",
      "Epoch 54, Loss: 0.3288, Train Acc: 0.9104\n",
      "Epoch 55, Loss: 0.3275, Train Acc: 0.9104\n",
      "Epoch 56, Loss: 0.3261, Train Acc: 0.9104\n",
      "Epoch 57, Loss: 0.3248, Train Acc: 0.9104\n",
      "Epoch 58, Loss: 0.3235, Train Acc: 0.9104\n",
      "Epoch 59, Loss: 0.3223, Train Acc: 0.9105\n",
      "Epoch 60, Loss: 0.3211, Train Acc: 0.9105\n",
      "Epoch 61, Loss: 0.3199, Train Acc: 0.9105\n",
      "Epoch 62, Loss: 0.3188, Train Acc: 0.9105\n",
      "Epoch 63, Loss: 0.3177, Train Acc: 0.9105\n",
      "Epoch 64, Loss: 0.3166, Train Acc: 0.9105\n",
      "Epoch 65, Loss: 0.3156, Train Acc: 0.9105\n",
      "Epoch 66, Loss: 0.3146, Train Acc: 0.9106\n",
      "Epoch 67, Loss: 0.3136, Train Acc: 0.9105\n",
      "Epoch 68, Loss: 0.3127, Train Acc: 0.9106\n",
      "Epoch 69, Loss: 0.3117, Train Acc: 0.9106\n",
      "Epoch 70, Loss: 0.3108, Train Acc: 0.9105\n",
      "Epoch 71, Loss: 0.3100, Train Acc: 0.9105\n",
      "Epoch 72, Loss: 0.3091, Train Acc: 0.9106\n",
      "Epoch 73, Loss: 0.3083, Train Acc: 0.9106\n",
      "Epoch 74, Loss: 0.3075, Train Acc: 0.9106\n",
      "Epoch 75, Loss: 0.3067, Train Acc: 0.9107\n",
      "Epoch 76, Loss: 0.3059, Train Acc: 0.9107\n",
      "Epoch 77, Loss: 0.3051, Train Acc: 0.9107\n",
      "Epoch 78, Loss: 0.3044, Train Acc: 0.9107\n",
      "Epoch 79, Loss: 0.3037, Train Acc: 0.9108\n",
      "Epoch 80, Loss: 0.3030, Train Acc: 0.9108\n",
      "Epoch 81, Loss: 0.3023, Train Acc: 0.9108\n",
      "Epoch 82, Loss: 0.3017, Train Acc: 0.9108\n",
      "Epoch 83, Loss: 0.3010, Train Acc: 0.9108\n",
      "Epoch 84, Loss: 0.3004, Train Acc: 0.9108\n",
      "Epoch 85, Loss: 0.2998, Train Acc: 0.9109\n",
      "Epoch 86, Loss: 0.2991, Train Acc: 0.9109\n",
      "Epoch 87, Loss: 0.2986, Train Acc: 0.9109\n",
      "Epoch 88, Loss: 0.2980, Train Acc: 0.9110\n",
      "Epoch 89, Loss: 0.2974, Train Acc: 0.9110\n",
      "Epoch 90, Loss: 0.2969, Train Acc: 0.9110\n",
      "Epoch 91, Loss: 0.2963, Train Acc: 0.9110\n",
      "Epoch 92, Loss: 0.2958, Train Acc: 0.9110\n",
      "Epoch 93, Loss: 0.2953, Train Acc: 0.9110\n",
      "Epoch 94, Loss: 0.2948, Train Acc: 0.9110\n",
      "Epoch 95, Loss: 0.2943, Train Acc: 0.9111\n",
      "Epoch 96, Loss: 0.2938, Train Acc: 0.9111\n",
      "Epoch 97, Loss: 0.2934, Train Acc: 0.9111\n",
      "Epoch 98, Loss: 0.2929, Train Acc: 0.9111\n",
      "Epoch 99, Loss: 0.2925, Train Acc: 0.9111\n",
      "Test Accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import DGLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, graph, features, labels, train_mask, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(graph, features)\n",
    "    loss = F.cross_entropy(out[train_mask], labels[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "# Suponiendo que ya tienes un train_mask y un test_mask para indicar qué nodos usar para entrenamiento y prueba\n",
    "train_mask = torch.rand(len(g.ndata['label'])) < 0.8  # Ejemplo para generar una máscara; ajusta según tus datos\n",
    "test_mask = ~train_mask\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(100):  # Número de épocas\n",
    "    loss = train(model, g, g.ndata['feat'], g.ndata['label'], train_mask, optimizer)\n",
    "    train_acc = evaluate(model, g, g.ndata['feat'], g.ndata['label'], train_mask)\n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "\n",
    "# Evaluación\n",
    "test_acc = evaluate(model, g, g.ndata['feat'], g.ndata['label'], test_mask)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
