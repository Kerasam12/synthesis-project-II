{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesDF  = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_classes.csv\")\n",
    "edgesDF = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_edgelist.csv\")\n",
    "featuresDF = pd.read_csv(r\"C:\\Users\\User\\Desktop\\UAB\\3rd-year\\2nd-semester\\synthesis project II\\elliptic_bitcoin_dataset\\elliptic_txs_features.csv\", header=None)\n",
    "featuresDF.columns = ['txId', 'timestep'] + ['f' + str(i) for i in range(165)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "      <th>timestep</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f155</th>\n",
       "      <th>f156</th>\n",
       "      <th>f157</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562153</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947382</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670883</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230460314</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511871</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        txId  class  timestep        f0        f1        f2         f3   \n",
       "0  230425980     -1         1 -0.171469 -0.184668 -1.201369  -0.121970  \\\n",
       "1    5530458     -1         1 -0.171484 -0.184668 -1.201369  -0.121970   \n",
       "2  232022460     -1         1 -0.172107 -0.184668 -1.201369  -0.121970   \n",
       "3  232438397      0         1  0.163054  1.963790 -0.646376  12.409294   \n",
       "4  230460314     -1         1  1.011523 -0.081127 -1.201369   1.153668   \n",
       "\n",
       "         f4        f5         f6  ...      f155      f156      f157      f158   \n",
       "0 -0.043875 -0.113002  -0.061584  ... -0.562153 -0.600999  1.461330  1.461369  \\\n",
       "1 -0.043875 -0.113002  -0.061584  ...  0.947382  0.673103 -0.979074 -0.978556   \n",
       "2 -0.043875 -0.113002  -0.061584  ...  0.670883  0.439728 -0.979074 -0.978556   \n",
       "3 -0.063725  9.782742  12.414558  ... -0.577099 -0.613614  0.241128  0.241406   \n",
       "4  0.333276  1.312656  -0.061584  ... -0.511871 -0.400422  0.517257  0.579382   \n",
       "\n",
       "       f159      f160      f161      f162      f163      f164  \n",
       "0  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
       "1  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
       "2 -0.098889 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
       "3  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
       "4  0.018279  0.277775  0.326394  1.293750  0.178136  0.179117  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class 2: LICIT // class 1: ILLICIT\n",
    "classesDF['class'] = classesDF['class'].map({'2': 0, '1': 1, 'unknown': -1})\n",
    "\n",
    "featuresDF = featuresDF.merge(classesDF, on='txId')\n",
    "\n",
    "# Move features 'class' to first column\n",
    "cols = list(featuresDF.columns)\n",
    "cols = cols[:1] + [cols[-1]] + cols[1:-1]\n",
    "featuresDF = featuresDF[cols]\n",
    "\n",
    "featuresDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "      <th>timestep</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f157</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>in_degree_edges</th>\n",
       "      <th>out_degree_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>[98374661]</td>\n",
       "      <td>[5530458]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>[230425980]</td>\n",
       "      <td>[232403360]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>[232000575]</td>\n",
       "      <td>[232438397, 232022462]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>[232022460, 232047899, 3877118, 230452718, 230...</td>\n",
       "      <td>[92491280]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230460314</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>[3272536, 230724244]</td>\n",
       "      <td>[230459870, 230460307, 230459688, 230570333, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        txId  class  timestep        f0        f1        f2         f3   \n",
       "0  230425980     -1         1 -0.171469 -0.184668 -1.201369  -0.121970  \\\n",
       "1    5530458     -1         1 -0.171484 -0.184668 -1.201369  -0.121970   \n",
       "2  232022460     -1         1 -0.172107 -0.184668 -1.201369  -0.121970   \n",
       "3  232438397      0         1  0.163054  1.963790 -0.646376  12.409294   \n",
       "4  230460314     -1         1  1.011523 -0.081127 -1.201369   1.153668   \n",
       "\n",
       "         f4        f5         f6  ...      f157      f158      f159      f160   \n",
       "0 -0.043875 -0.113002  -0.061584  ...  1.461330  1.461369  0.018279 -0.087490  \\\n",
       "1 -0.043875 -0.113002  -0.061584  ... -0.979074 -0.978556  0.018279 -0.087490   \n",
       "2 -0.043875 -0.113002  -0.061584  ... -0.979074 -0.978556 -0.098889 -0.106715   \n",
       "3 -0.063725  9.782742  12.414558  ...  0.241128  0.241406  1.072793  0.085530   \n",
       "4  0.333276  1.312656  -0.061584  ...  0.517257  0.579382  0.018279  0.277775   \n",
       "\n",
       "       f161      f162      f163      f164   \n",
       "0 -0.131155 -0.097524 -0.120613 -0.119792  \\\n",
       "1 -0.131155 -0.097524 -0.120613 -0.119792   \n",
       "2 -0.131155 -0.183671 -0.120613 -0.119792   \n",
       "3 -0.131155  0.677799 -0.120613 -0.119792   \n",
       "4  0.326394  1.293750  0.178136  0.179117   \n",
       "\n",
       "                                     in_degree_edges   \n",
       "0                                         [98374661]  \\\n",
       "1                                        [230425980]   \n",
       "2                                        [232000575]   \n",
       "3  [232022460, 232047899, 3877118, 230452718, 230...   \n",
       "4                               [3272536, 230724244]   \n",
       "\n",
       "                                    out_degree_edges  \n",
       "0                                          [5530458]  \n",
       "1                                        [232403360]  \n",
       "2                             [232438397, 232022462]  \n",
       "3                                         [92491280]  \n",
       "4  [230459870, 230460307, 230459688, 230570333, 2...  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_degree_dict = {}\n",
    "out_degree_dict = {}\n",
    "\n",
    "for _, row in edgesDF.iterrows():\n",
    "    txId1, txId2 = row['txId1'], row['txId2']\n",
    "    \n",
    "    if txId2 not in in_degree_dict:\n",
    "        in_degree_dict[txId2] = []\n",
    "    in_degree_dict[txId2].append(txId1)\n",
    "    \n",
    "    if txId1 not in out_degree_dict:\n",
    "        out_degree_dict[txId1] = []\n",
    "    out_degree_dict[txId1].append(txId2)\n",
    "\n",
    "# Filtrar los diccionarios para incluir solo IDs presentes en featuresDF_example\n",
    "valid_ids = set(featuresDF['txId'])\n",
    "\n",
    "in_degree_dict_filtered = {k: [v for v in vals if v in valid_ids] for k, vals in in_degree_dict.items() if k in valid_ids}\n",
    "out_degree_dict_filtered = {k: [v for v in vals if v in valid_ids] for k, vals in out_degree_dict.items() if k in valid_ids}\n",
    "\n",
    "# Funciones para obtener las listas de conexiones\n",
    "def get_in_degree_connections(txId):\n",
    "    return in_degree_dict_filtered.get(txId, [])\n",
    "\n",
    "def get_out_degree_connections(txId):\n",
    "    return out_degree_dict_filtered.get(txId, [])\n",
    "\n",
    "# Aplicar las funciones para crear las nuevas columnas\n",
    "featuresDF['in_degree_edges'] = featuresDF['txId'].apply(get_in_degree_connections)\n",
    "featuresDF['out_degree_edges'] = featuresDF['txId'].apply(get_out_degree_connections)\n",
    "\n",
    "featuresDF.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "      <th>timestep</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f155</th>\n",
       "      <th>f156</th>\n",
       "      <th>f157</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562153</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947382</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670883</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232438397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230460314</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511871</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        txId  class  timestep        f0        f1        f2         f3   \n",
       "0  230425980     -1         1 -0.171469 -0.184668 -1.201369  -0.121970  \\\n",
       "1    5530458     -1         1 -0.171484 -0.184668 -1.201369  -0.121970   \n",
       "2  232022460     -1         1 -0.172107 -0.184668 -1.201369  -0.121970   \n",
       "3  232438397      0         1  0.163054  1.963790 -0.646376  12.409294   \n",
       "4  230460314     -1         1  1.011523 -0.081127 -1.201369   1.153668   \n",
       "\n",
       "         f4        f5         f6  ...      f155      f156      f157      f158   \n",
       "0 -0.043875 -0.113002  -0.061584  ... -0.562153 -0.600999  1.461330  1.461369  \\\n",
       "1 -0.043875 -0.113002  -0.061584  ...  0.947382  0.673103 -0.979074 -0.978556   \n",
       "2 -0.043875 -0.113002  -0.061584  ...  0.670883  0.439728 -0.979074 -0.978556   \n",
       "3 -0.063725  9.782742  12.414558  ... -0.577099 -0.613614  0.241128  0.241406   \n",
       "4  0.333276  1.312656  -0.061584  ... -0.511871 -0.400422  0.517257  0.579382   \n",
       "\n",
       "       f159      f160      f161      f162      f163      f164  \n",
       "0  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
       "1  0.018279 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  \n",
       "2 -0.098889 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  \n",
       "3  1.072793  0.085530 -0.131155  0.677799 -0.120613 -0.119792  \n",
       "4  0.018279  0.277775  0.326394  1.293750  0.178136  0.179117  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDF.drop(['in_degree_edges', 'out_degree_edges'], axis=1, inplace=True)\n",
    "featuresDF.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX = featuresDF.drop(['txId', 'class'], axis=1).values.astype(float)\\ny = featuresDF['class'].values.astype(float)\\n\\n# Convertir -1 en 'unknown' a NaN para el filtrado\\ny[y == -1] = np.nan\\n\\n# Dividir los datos en conjuntos etiquetados y no etiquetados\\nis_labeled = ~np.isnan(y)\\nX_labeled = X[is_labeled]\\ny_labeled = y[is_labeled]\\n\\n# CodificaciÃ³n One-hot de las etiquetas\\ny_labeled_onehot = to_categorical(y_labeled, num_classes=2)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled_onehot, test_size=0.2, random_state=42)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X = featuresDF.drop(['txId', 'class'], axis=1).values.astype(float)\n",
    "y = featuresDF['class'].values.astype(float)\n",
    "\n",
    "# Convertir -1 en 'unknown' a NaN para el filtrado\n",
    "y[y == -1] = np.nan\n",
    "\n",
    "# Dividir los datos en conjuntos etiquetados y no etiquetados\n",
    "is_labeled = ~np.isnan(y)\n",
    "X_labeled = X[is_labeled]\n",
    "y_labeled = y[is_labeled]\n",
    "\n",
    "# CodificaciÃ³n One-hot de las etiquetas\n",
    "y_labeled_onehot = to_categorical(y_labeled, num_classes=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled_onehot, test_size=0.2, random_state=42)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labeled: [0. 0. 0. ... 1. 0. 1.]\n",
      "42019\n",
      "4545\n",
      "X_licitos_balanced: 4000\n",
      "X_licitos_eval:  38019\n",
      "y_licitos_balanced: 4000\n",
      "y_licitos_balanced: 38019\n",
      "X_ilicitos_balanced: 4000\n",
      "X_ilicitos_eval:  545\n",
      "y_ilicitos_balanced: 4000\n",
      "y_ilicitos_balanced: 545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = featuresDF.drop(['txId', 'class'], axis=1).values.astype(float)\n",
    "y = featuresDF['class'].values.astype(float)\n",
    "\n",
    "is_labeled = y >= 0  # Esto seleccionarÃ¡ clases 1 y 2 como etiquetadas\n",
    "is_unlabeled = y == -1  # Esto seleccionarÃ¡ clases -1 como no etiquetadas\n",
    "\n",
    "X_labeled = X[is_labeled]\n",
    "y_labeled = y[is_labeled]\n",
    "print(\"y_labeled:\", y_labeled)\n",
    "X_unlabeled = X[is_unlabeled]\n",
    "\n",
    "# CodificaciÃ³n One-hot de las etiquetas para los datos etiquetados\n",
    "y_labeled_onehot = to_categorical(y_labeled - 1, num_classes=2)  # Ajustar las clases a 0 y 1\n",
    "\n",
    "# DivisiÃ³n de los datos etiquetados en lÃ­citos e ilÃ­citos\n",
    "X_licitos = X_labeled[y_labeled == 0]\n",
    "print(len(X_licitos))\n",
    "y_licitos = y_labeled_onehot[y_labeled == 0]\n",
    "\n",
    "X_ilicitos = X_labeled[y_labeled == 1]\n",
    "print(len(X_ilicitos))\n",
    "y_ilicitos = y_labeled_onehot[y_labeled == 1]\n",
    "\n",
    "#LICITOS\n",
    "X_licitos_balanced = X_licitos[:4000]\n",
    "print(\"X_licitos_balanced:\",len(X_licitos_balanced))\n",
    "X_licitos_eval = X_licitos[4000:]\n",
    "print(\"X_licitos_eval: \", len(X_licitos_eval))\n",
    "\n",
    "y_licitos_balanced= y_licitos[:4000]\n",
    "print(\"y_licitos_balanced:\",len(y_licitos_balanced))\n",
    "y_licitos_eval = y_licitos[4000:]\n",
    "print(\"y_licitos_balanced:\",len(y_licitos_eval))\n",
    "\n",
    "#ILICITOS\n",
    "X_ilicitos_balanced = X_ilicitos[:4000]\n",
    "print(\"X_ilicitos_balanced:\",len(X_ilicitos_balanced))\n",
    "X_ilicitos_eval = X_ilicitos[4000:]\n",
    "print(\"X_ilicitos_eval: \", len(X_ilicitos_eval))\n",
    "\n",
    "y_ilicitos_balanced= y_ilicitos[:4000]\n",
    "print(\"y_ilicitos_balanced:\",len(y_ilicitos_balanced))\n",
    "y_ilicitos_eval = y_ilicitos[4000:]\n",
    "print(\"y_ilicitos_balanced:\",len(y_ilicitos_eval))\n",
    "\n",
    "# Combinar y mezclar los datos balanceados para el entrenamiento\n",
    "X_train_balanced = np.concatenate([X_licitos_balanced, X_ilicitos_balanced])\n",
    "y_train_balanced = np.concatenate([y_licitos_balanced, y_ilicitos_balanced])\n",
    "X_train_balanced, y_train_balanced = shuffle(X_train_balanced, y_train_balanced, random_state=42)\n",
    "\n",
    "# Combinar los datos reservados para evaluaciÃ³n\n",
    "X_eval = np.concatenate([X_licitos_eval, X_ilicitos_eval])\n",
    "y_eval = np.concatenate([y_licitos_eval, y_ilicitos_eval])\n",
    "\n",
    "# Asignar los datos no etiquetados como conjunto de test (para el autoentrenamiento o predicciones futuras)\n",
    "X_test = X_unlabeled\n",
    "\n",
    "# Ahora tienes:\n",
    "# X_train_balanced, y_train_balanced: Datos de entrenamiento balanceados.\n",
    "# X_eval, y_eval: Datos reservados para la evaluaciÃ³n final del modelo.\n",
    "# X_test: Datos no etiquetados para predicciones futuras o autoentrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 166)\n",
      "(157205, 166)\n",
      "(8000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_balanced.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_balanced.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(37251, 166)\\n(9313, 166)\\n(37251, 2)\\n(9313, 2)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\"\"\"\n",
    "(37251, 166)\n",
    "(9313, 166)\n",
    "(37251, 2)\n",
    "(9313, 2)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9516\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9860\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9871\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9881\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9884\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9890\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9894\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9896\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9898\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9906\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9909\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9912\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9912\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9920\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9921\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9923\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9923\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9921\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ny_pred_labels = np.argmax(y_pred, axis=1)\\ny_test_labels = np.argmax(y_test, axis=1)\\nconfusion_mtx = confusion_matrix(y_test_labels, y_pred_labels)\\nprint(confusion_mtx)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_balanced.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # 2 clases: lÃ­citas e ilÃ­citas\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo con datos etiquetados\n",
    "model.fit(X_train_balanced, y_train_balanced, epochs=20, batch_size=100)\n",
    "\n",
    "# Predecir y evaluar con datos de prueba\n",
    "#y_pred = model.predict(X_test)\n",
    "\n",
    "\"\"\"\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "confusion_mtx = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(confusion_mtx)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FunciÃ³n de auto-entrenamiento adaptada para datos tabulares\n",
    "def self_training(model, X_labeled, y_labeled, X_unlabeled, threshold):\n",
    "    epoch = 0\n",
    "    while len(X_unlabeled) > 0:\n",
    "        # Entrenar el modelo\n",
    "        model.fit(X_labeled, y_labeled, epochs=1, batch_size=100)\n",
    "\n",
    "        # Predecir etiquetas para datos no etiquetados\n",
    "        predictions = model.predict(X_unlabeled)\n",
    "        confidences = np.max(predictions, axis=1)\n",
    "        high_confidence_indices = confidences > threshold\n",
    "\n",
    "        # Seleccionar datos con alta confianza\n",
    "        X_high_confidence = X_unlabeled[high_confidence_indices]\n",
    "        y_high_confidence = predictions[high_confidence_indices]\n",
    "\n",
    "        # Actualizar conjuntos etiquetados\n",
    "        X_labeled = np.concatenate([X_labeled, X_high_confidence])\n",
    "        y_labeled = np.concatenate([y_labeled, y_high_confidence])\n",
    "\n",
    "        # Eliminar los seleccionados de los datos no etiquetados\n",
    "        X_unlabeled = np.delete(X_unlabeled, high_confidence_indices, axis=0)\n",
    "        epoch += 1\n",
    "        print(f\"IteraciÃ³n {epoch+1}, Datos aÃ±adidos: {len(X_high_confidence)}, Datos faltantes: {len(X_unlabeled)}\")\n",
    "\n",
    "    return model, X_labeled, y_labeled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calcular la precisiÃ³n y la matriz de confusiÃ³n\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    confusion_mtx = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "    \n",
    "    return accuracy, confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/80 [..............................] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9925\n",
      "4913/4913 [==============================] - 6s 1ms/step\n",
      "IteraciÃ³n 2, Datos aÃ±adidos: 142873, Datos faltantes: 14332\n",
      "1509/1509 [==============================] - 4s 2ms/step - loss: 0.0224 - accuracy: 0.9996\n",
      "448/448 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 3, Datos aÃ±adidos: 158, Datos faltantes: 14174\n",
      "1511/1511 [==============================] - 3s 2ms/step - loss: 0.0227 - accuracy: 0.9996\n",
      "443/443 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 4, Datos aÃ±adidos: 51, Datos faltantes: 14123\n",
      "1511/1511 [==============================] - 4s 2ms/step - loss: 0.0227 - accuracy: 0.9996\n",
      "442/442 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 5, Datos aÃ±adidos: 145, Datos faltantes: 13978\n",
      "1513/1513 [==============================] - 4s 2ms/step - loss: 0.0230 - accuracy: 0.9996\n",
      "437/437 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 6, Datos aÃ±adidos: 13, Datos faltantes: 13965\n",
      "1513/1513 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9996\n",
      "437/437 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 7, Datos aÃ±adidos: 15, Datos faltantes: 13950\n",
      "1513/1513 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9996\n",
      "436/436 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 8, Datos aÃ±adidos: 16, Datos faltantes: 13934\n",
      "1513/1513 [==============================] - 3s 2ms/step - loss: 0.0231 - accuracy: 0.9997\n",
      "436/436 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 9, Datos aÃ±adidos: 23, Datos faltantes: 13911\n",
      "1513/1513 [==============================] - 4s 3ms/step - loss: 0.0231 - accuracy: 0.9997\n",
      "435/435 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 10, Datos aÃ±adidos: 9, Datos faltantes: 13902\n",
      "1514/1514 [==============================] - 5s 3ms/step - loss: 0.0231 - accuracy: 0.9997\n",
      "435/435 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 11, Datos aÃ±adidos: 13, Datos faltantes: 13889\n",
      "1514/1514 [==============================] - 3s 2ms/step - loss: 0.0231 - accuracy: 0.9997\n",
      "435/435 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 12, Datos aÃ±adidos: 28, Datos faltantes: 13861\n",
      "1514/1514 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "434/434 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 13, Datos aÃ±adidos: 7, Datos faltantes: 13854\n",
      "1514/1514 [==============================] - 4s 2ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "433/433 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 14, Datos aÃ±adidos: 29, Datos faltantes: 13825\n",
      "1514/1514 [==============================] - 5s 3ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "433/433 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 15, Datos aÃ±adidos: 0, Datos faltantes: 13825\n",
      "1514/1514 [==============================] - 4s 3ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "433/433 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 16, Datos aÃ±adidos: 8, Datos faltantes: 13817\n",
      "1514/1514 [==============================] - 5s 3ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "432/432 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 17, Datos aÃ±adidos: 17, Datos faltantes: 13800\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "432/432 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 18, Datos aÃ±adidos: 7, Datos faltantes: 13793\n",
      "1515/1515 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9997\n",
      "432/432 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 19, Datos aÃ±adidos: 16, Datos faltantes: 13777\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "431/431 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 20, Datos aÃ±adidos: 6, Datos faltantes: 13771\n",
      "1515/1515 [==============================] - 5s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "431/431 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 21, Datos aÃ±adidos: 1, Datos faltantes: 13770\n",
      "1515/1515 [==============================] - 5s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "431/431 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 22, Datos aÃ±adidos: 6, Datos faltantes: 13764\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "431/431 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 23, Datos aÃ±adidos: 33, Datos faltantes: 13731\n",
      "1515/1515 [==============================] - 3s 2ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "430/430 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 24, Datos aÃ±adidos: 14, Datos faltantes: 13717\n",
      "1515/1515 [==============================] - 4s 2ms/step - loss: 0.0234 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 25, Datos aÃ±adidos: 2, Datos faltantes: 13715\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 26, Datos aÃ±adidos: 0, Datos faltantes: 13715\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 27, Datos aÃ±adidos: 2, Datos faltantes: 13713\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 28, Datos aÃ±adidos: 3, Datos faltantes: 13710\n",
      "1515/1515 [==============================] - 4s 3ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 29, Datos aÃ±adidos: 1, Datos faltantes: 13709\n",
      "1515/1515 [==============================] - 3s 2ms/step - loss: 0.0233 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 30, Datos aÃ±adidos: 9, Datos faltantes: 13700\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9997\n",
      "429/429 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 31, Datos aÃ±adidos: 2, Datos faltantes: 13698\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "429/429 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 32, Datos aÃ±adidos: 3, Datos faltantes: 13695\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9997\n",
      "428/428 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 33, Datos aÃ±adidos: 9, Datos faltantes: 13686\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "428/428 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 34, Datos aÃ±adidos: 1, Datos faltantes: 13685\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "428/428 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 35, Datos aÃ±adidos: 2, Datos faltantes: 13683\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "428/428 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 36, Datos aÃ±adidos: 2, Datos faltantes: 13681\n",
      "1516/1516 [==============================] - 9s 6ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "428/428 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 37, Datos aÃ±adidos: 5, Datos faltantes: 13676\n",
      "1516/1516 [==============================] - 4s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "428/428 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 38, Datos aÃ±adidos: 8, Datos faltantes: 13668\n",
      "1516/1516 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "428/428 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 39, Datos aÃ±adidos: 5, Datos faltantes: 13663\n",
      "1516/1516 [==============================] - 4s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 40, Datos aÃ±adidos: 2, Datos faltantes: 13661\n",
      "1516/1516 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 41, Datos aÃ±adidos: 6, Datos faltantes: 13655\n",
      "1516/1516 [==============================] - 5s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 42, Datos aÃ±adidos: 1, Datos faltantes: 13654\n",
      "1516/1516 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 43, Datos aÃ±adidos: 2, Datos faltantes: 13652\n",
      "1516/1516 [==============================] - 5s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 44, Datos aÃ±adidos: 0, Datos faltantes: 13652\n",
      "1516/1516 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 45, Datos aÃ±adidos: 4, Datos faltantes: 13648\n",
      "1516/1516 [==============================] - 5s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 46, Datos aÃ±adidos: 10, Datos faltantes: 13638\n",
      "1516/1516 [==============================] - 5s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "427/427 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 47, Datos aÃ±adidos: 22, Datos faltantes: 13616\n",
      "1516/1516 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 48, Datos aÃ±adidos: 1, Datos faltantes: 13615\n",
      "1516/1516 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 49, Datos aÃ±adidos: 0, Datos faltantes: 13615\n",
      "1516/1516 [==============================] - 5s 3ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 50, Datos aÃ±adidos: 1, Datos faltantes: 13614\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 51, Datos aÃ±adidos: 7, Datos faltantes: 13607\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 52, Datos aÃ±adidos: 1, Datos faltantes: 13606\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 0s 1ms/step\n",
      "IteraciÃ³n 53, Datos aÃ±adidos: 0, Datos faltantes: 13606\n",
      "1516/1516 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 54, Datos aÃ±adidos: 2, Datos faltantes: 13604\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 55, Datos aÃ±adidos: 1, Datos faltantes: 13603\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "426/426 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 56, Datos aÃ±adidos: 3, Datos faltantes: 13600\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 57, Datos aÃ±adidos: 1, Datos faltantes: 13599\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 58, Datos aÃ±adidos: 0, Datos faltantes: 13599\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 59, Datos aÃ±adidos: 8, Datos faltantes: 13591\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 60, Datos aÃ±adidos: 0, Datos faltantes: 13591\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 61, Datos aÃ±adidos: 8, Datos faltantes: 13583\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 2s 5ms/step\n",
      "IteraciÃ³n 62, Datos aÃ±adidos: 2, Datos faltantes: 13581\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 63, Datos aÃ±adidos: 0, Datos faltantes: 13581\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 64, Datos aÃ±adidos: 0, Datos faltantes: 13581\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 65, Datos aÃ±adidos: 1, Datos faltantes: 13580\n",
      "1517/1517 [==============================] - 6s 4ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 66, Datos aÃ±adidos: 1, Datos faltantes: 13579\n",
      "1517/1517 [==============================] - 9s 6ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 2s 5ms/step\n",
      "IteraciÃ³n 67, Datos aÃ±adidos: 1, Datos faltantes: 13578\n",
      "1517/1517 [==============================] - 6s 4ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 68, Datos aÃ±adidos: 0, Datos faltantes: 13578\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 69, Datos aÃ±adidos: 3, Datos faltantes: 13575\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 70, Datos aÃ±adidos: 1, Datos faltantes: 13574\n",
      "1517/1517 [==============================] - 5s 4ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 71, Datos aÃ±adidos: 0, Datos faltantes: 13574\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "425/425 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 72, Datos aÃ±adidos: 18, Datos faltantes: 13556\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 73, Datos aÃ±adidos: 1, Datos faltantes: 13555\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 74, Datos aÃ±adidos: 3, Datos faltantes: 13552\n",
      "1517/1517 [==============================] - 5s 4ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 75, Datos aÃ±adidos: 3, Datos faltantes: 13549\n",
      "1517/1517 [==============================] - 5s 4ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 76, Datos aÃ±adidos: 0, Datos faltantes: 13549\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 77, Datos aÃ±adidos: 1, Datos faltantes: 13548\n",
      "1517/1517 [==============================] - 6s 4ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 78, Datos aÃ±adidos: 0, Datos faltantes: 13548\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "424/424 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 79, Datos aÃ±adidos: 17, Datos faltantes: 13531\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 80, Datos aÃ±adidos: 1, Datos faltantes: 13530\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 81, Datos aÃ±adidos: 0, Datos faltantes: 13530\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 82, Datos aÃ±adidos: 1, Datos faltantes: 13529\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 83, Datos aÃ±adidos: 0, Datos faltantes: 13529\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 84, Datos aÃ±adidos: 1, Datos faltantes: 13528\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 85, Datos aÃ±adidos: 0, Datos faltantes: 13528\n",
      "1517/1517 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 0s 1ms/step\n",
      "IteraciÃ³n 86, Datos aÃ±adidos: 0, Datos faltantes: 13528\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 87, Datos aÃ±adidos: 8, Datos faltantes: 13520\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 88, Datos aÃ±adidos: 0, Datos faltantes: 13520\n",
      "1517/1517 [==============================] - 4s 2ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "IteraciÃ³n 89, Datos aÃ±adidos: 5, Datos faltantes: 13515\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 90, Datos aÃ±adidos: 0, Datos faltantes: 13515\n",
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 91, Datos aÃ±adidos: 0, Datos faltantes: 13515\n",
      "1517/1517 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 92, Datos aÃ±adidos: 10, Datos faltantes: 13505\n",
      "1517/1517 [==============================] - 7s 5ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "423/423 [==============================] - 2s 4ms/step\n",
      "IteraciÃ³n 93, Datos aÃ±adidos: 0, Datos faltantes: 13505\n",
      "1517/1517 [==============================] - 7s 5ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "423/423 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 94, Datos aÃ±adidos: 2, Datos faltantes: 13503\n",
      "1518/1518 [==============================] - 6s 4ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "422/422 [==============================] - 2s 4ms/step\n",
      "IteraciÃ³n 95, Datos aÃ±adidos: 5, Datos faltantes: 13498\n",
      "1518/1518 [==============================] - 7s 4ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "422/422 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 96, Datos aÃ±adidos: 1, Datos faltantes: 13497\n",
      "1518/1518 [==============================] - 11s 7ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "422/422 [==============================] - 2s 5ms/step\n",
      "IteraciÃ³n 97, Datos aÃ±adidos: 0, Datos faltantes: 13497\n",
      "1518/1518 [==============================] - 15s 10ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "422/422 [==============================] - 2s 5ms/step\n",
      "IteraciÃ³n 98, Datos aÃ±adidos: 0, Datos faltantes: 13497\n",
      "1518/1518 [==============================] - 10s 6ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "422/422 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 99, Datos aÃ±adidos: 1, Datos faltantes: 13496\n",
      "1518/1518 [==============================] - 6s 4ms/step - loss: 0.0236 - accuracy: 0.9998\n",
      "422/422 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 100, Datos aÃ±adidos: 250, Datos faltantes: 13246\n",
      "1520/1520 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 2s 4ms/step\n",
      "IteraciÃ³n 101, Datos aÃ±adidos: 3, Datos faltantes: 13243\n",
      "1520/1520 [==============================] - 7s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 102, Datos aÃ±adidos: 0, Datos faltantes: 13243\n",
      "1520/1520 [==============================] - 8s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 103, Datos aÃ±adidos: 3, Datos faltantes: 13240\n",
      "1520/1520 [==============================] - 7s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 104, Datos aÃ±adidos: 0, Datos faltantes: 13240\n",
      "1520/1520 [==============================] - 7s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 105, Datos aÃ±adidos: 0, Datos faltantes: 13240\n",
      "1520/1520 [==============================] - 8s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 3s 6ms/step\n",
      "IteraciÃ³n 106, Datos aÃ±adidos: 7, Datos faltantes: 13233\n",
      "1520/1520 [==============================] - 7s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 107, Datos aÃ±adidos: 0, Datos faltantes: 13233\n",
      "1520/1520 [==============================] - 7s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 108, Datos aÃ±adidos: 2, Datos faltantes: 13231\n",
      "1520/1520 [==============================] - 7s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 109, Datos aÃ±adidos: 1, Datos faltantes: 13230\n",
      "1520/1520 [==============================] - 13s 9ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 2s 4ms/step\n",
      "IteraciÃ³n 110, Datos aÃ±adidos: 0, Datos faltantes: 13230\n",
      "1520/1520 [==============================] - 13s 8ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 2s 5ms/step\n",
      "IteraciÃ³n 111, Datos aÃ±adidos: 3, Datos faltantes: 13227\n",
      "1520/1520 [==============================] - 14s 9ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 3s 8ms/step\n",
      "IteraciÃ³n 112, Datos aÃ±adidos: 0, Datos faltantes: 13227\n",
      "1520/1520 [==============================] - 10s 7ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 3s 6ms/step\n",
      "IteraciÃ³n 113, Datos aÃ±adidos: 0, Datos faltantes: 13227\n",
      "1520/1520 [==============================] - 11s 7ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 114, Datos aÃ±adidos: 1, Datos faltantes: 13226\n",
      "1520/1520 [==============================] - 13s 9ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 2s 4ms/step\n",
      "IteraciÃ³n 115, Datos aÃ±adidos: 2, Datos faltantes: 13224\n",
      "1520/1520 [==============================] - 11s 7ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 2s 4ms/step\n",
      "IteraciÃ³n 116, Datos aÃ±adidos: 0, Datos faltantes: 13224\n",
      "1520/1520 [==============================] - 9s 6ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 117, Datos aÃ±adidos: 0, Datos faltantes: 13224\n",
      "1520/1520 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 118, Datos aÃ±adidos: 0, Datos faltantes: 13224\n",
      "1520/1520 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 119, Datos aÃ±adidos: 0, Datos faltantes: 13224\n",
      "1520/1520 [==============================] - 5s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 120, Datos aÃ±adidos: 0, Datos faltantes: 13224\n",
      "1520/1520 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 121, Datos aÃ±adidos: 1, Datos faltantes: 13223\n",
      "1520/1520 [==============================] - 8s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 122, Datos aÃ±adidos: 1, Datos faltantes: 13222\n",
      "1520/1520 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 123, Datos aÃ±adidos: 0, Datos faltantes: 13222\n",
      "1520/1520 [==============================] - 4s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 124, Datos aÃ±adidos: 0, Datos faltantes: 13222\n",
      "1520/1520 [==============================] - 8s 5ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 125, Datos aÃ±adidos: 0, Datos faltantes: 13222\n",
      "1520/1520 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 126, Datos aÃ±adidos: 4, Datos faltantes: 13218\n",
      "1520/1520 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 127, Datos aÃ±adidos: 0, Datos faltantes: 13218\n",
      "1520/1520 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 128, Datos aÃ±adidos: 0, Datos faltantes: 13218\n",
      "1520/1520 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 129, Datos aÃ±adidos: 1, Datos faltantes: 13217\n",
      "1520/1520 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "414/414 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 130, Datos aÃ±adidos: 13, Datos faltantes: 13204\n",
      "1521/1521 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "413/413 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 131, Datos aÃ±adidos: 0, Datos faltantes: 13204\n",
      "1521/1521 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "413/413 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 132, Datos aÃ±adidos: 0, Datos faltantes: 13204\n",
      "1521/1521 [==============================] - 5s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "413/413 [==============================] - 1s 2ms/step\n",
      "IteraciÃ³n 133, Datos aÃ±adidos: 0, Datos faltantes: 13204\n",
      "1521/1521 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9998\n",
      "413/413 [==============================] - 1s 3ms/step\n",
      "IteraciÃ³n 134, Datos aÃ±adidos: 0, Datos faltantes: 13204\n",
      " 403/1521 [======>.......................] - ETA: 5s - loss: 0.0237 - accuracy: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_self_trained, X_self_labeled, y_self_labeled \u001b[38;5;241m=\u001b[39m \u001b[43mself_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m# Evaluar el modelo despuÃ©s del autoentrenamiento\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mfinal_accuracy, final_confusion_mtx = evaluate_model(model_self_trained, X_test, y_test)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mprint(\"Matriz de confusiÃ³n:\\n\", final_confusion_mtx)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m, in \u001b[0;36mself_training\u001b[1;34m(model, X_labeled, y_labeled, X_unlabeled, threshold)\u001b[0m\n\u001b[0;32m      3\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_unlabeled) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_labeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_labeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Predecir etiquetas para datos no etiquetados\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_unlabeled)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1691\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1689\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1690\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1691\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    327\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\generic_utils.py:296\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    293\u001b[0m         info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[1;32m--> 296\u001b[0m     \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\io_utils.py:79\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     77\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m         \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py:610\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py:507\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py:213\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     f()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\zmq\\sugar\\socket.py:688\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    681\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    682\u001b[0m             data,\n\u001b[0;32m    683\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    684\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    685\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    686\u001b[0m         )\n\u001b[0;32m    687\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_self_trained, X_self_labeled, y_self_labeled = self_training(model, X_train_balanced, y_train_balanced, X_test, threshold=0.9)\n",
    "\n",
    "\"\"\"\n",
    "# Evaluar el modelo despuÃ©s del autoentrenamiento\n",
    "final_accuracy, final_confusion_mtx = evaluate_model(model_self_trained, X_test, y_test)\n",
    "print(\"DespuÃ©s del autoentrenamiento:\")\n",
    "print(\"PrecisiÃ³n:\", final_accuracy)\n",
    "print(\"Matriz de confusiÃ³n:\\n\", final_confusion_mtx)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_self_labeled\n",
    "#deberian ser 203769 creo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_self_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, conf_mtrx = evaluate_model(model_self_trained, X_eval, y_eval)\n",
    "\n",
    "print(\"accuracy:\", acc)\n",
    "print(\"confusion matrix:\", conf_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
